{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c895eb-5095-4c5c-8fad-3dce570e628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_scatter\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import models\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "from torch_geometric.nn import aggr\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from sklearn import preprocessing\n",
    "import squidpy as sq\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "datadir = \"/data1/shahs3/users/mezallj1/data/osmfish\"\n",
    "figdir = \"/data1/shahs3/users/mezallj1/figures/osmfish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb459f36-27be-4bc1-9b84-efecc5575437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrafitiEncoderLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GrafitiEncoderLayer, self).__init__(aggr='add')\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        edge_attr = edge_attr.to(x_j.dtype) \n",
    "        return x_j / edge_attr.unsqueeze(-1) \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        ret = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        ret = self.lin(ret) \n",
    "        return F.leaky_relu(ret, negative_slope=0.01)\n",
    "    \n",
    "class GrafitiDecoderLayer(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GrafitiDecoderLayer, self).__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def message(self, x_j, edge_attr): \n",
    "        edge_attr = edge_attr.to(x_j.dtype)\n",
    "        degree = x_j.size(0) \n",
    "        degree_normalized_message = x_j / edge_attr.unsqueeze(-1) \n",
    "        res = degree_normalized_message / degree\n",
    "        return res\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size=None):\n",
    "        res = torch_scatter.scatter_mean(inputs, index, dim=0, dim_size=dim_size)\n",
    "        return res\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        aggr_out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "        transformed_features = x - aggr_out\n",
    "        transformed_features = self.lin(transformed_features) \n",
    "        return F.leaky_relu(transformed_features, negative_slope=0.01)\n",
    "    \n",
    "\n",
    "class GrafitiEncoderModule(torch.nn.Module):\n",
    "    def __init__(self, in_dim, layers=[10,10]):\n",
    "        super(GrafitiEncoderModule, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.conv = nn.ModuleList()\n",
    "        lhidden_dim = self.layers[0]\n",
    "        self.conv.append(GrafitiEncoderLayer(in_dim, lhidden_dim))\n",
    "        for hidden_dim in self.layers[1:]:\n",
    "            self.conv.append(GrafitiEncoderLayer(lhidden_dim, hidden_dim))\n",
    "            lhidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv in self.conv:\n",
    "            x = conv(x, edge_index=edge_index, edge_attr=edge_attr).relu()\n",
    "        return x\n",
    "\n",
    "class GrafitiDecoderModule(torch.nn.Module):\n",
    "    def __init__(self, in_dim, layers=[30,30]):\n",
    "        super(GrafitiDecoderModule, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.conv = nn.ModuleList()\n",
    "        lhidden_dim = self.layers[0]\n",
    "        self.conv.append(GrafitiDecoderLayer(in_dim, lhidden_dim))\n",
    "        for hidden_dim in self.layers[1:]:\n",
    "            self.conv.append(GrafitiDecoderLayer(lhidden_dim, hidden_dim))\n",
    "            lhidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for conv in self.conv:\n",
    "            x = conv(x, edge_index=edge_index, edge_attr=edge_attr).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0431dad5-cd6c-4b7b-9894-9e81f8a4fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAE(object):\n",
    "\n",
    "    def __init__(self, adata, layers=[10,10], lr=0.00001, distance_threshold=None, exponent=2, distance_scale=None):\n",
    "        self.lr = lr\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(\"Generating PyTorch Geometric Dataset...\")\n",
    "        if distance_threshold is not None:\n",
    "            distances = adata.obsp[\"spatial_distances\"]\n",
    "            connectiv = adata.obsp[\"spatial_connectivities\"]\n",
    "            rows, cols = distances.nonzero()\n",
    "            for row, col in zip(rows, cols):\n",
    "                if distances[row, col] > distance_threshold:\n",
    "                    connectiv[row, col] = 0\n",
    "            adata.obsp[\"spatial_connectivities\"] = connectiv\n",
    "        edges = adata.obsp[\"spatial_connectivities\"].nonzero()\n",
    "        x = torch.from_numpy(adata.X).float().to(self.device)\n",
    "        e = torch.from_numpy(np.array(edges)).type(torch.int64).to(self.device)\n",
    "        attrs = [adata.obsp[\"spatial_distances\"][x, y] for x, y in zip(*edges)]\n",
    "        if distance_scale is not None:\n",
    "            scaler = preprocessing.MinMaxScaler(feature_range=(0, distance_scale))\n",
    "            attrs = scaler.fit_transform(np.array(attrs).reshape(-1, 1)).reshape(1, -1)\n",
    "            attrs = 1. / (np.array(attrs) ** exponent)\n",
    "            attrs = attrs[0]\n",
    "        else:\n",
    "            attrs = np.array(attrs)\n",
    "        data = Data(x=x, edge_index=e, edge_attr=torch.from_numpy(attrs).to(self.device))\n",
    "        self.adata = adata\n",
    "        self.encoder_layers = layers\n",
    "        self.decoder_layers = list(reversed(layers[1:])) + [data.num_features]\n",
    "        print(\"Setting up Model...\")\n",
    "        self.encoder = GrafitiEncoderModule(data.num_features, layers=self.encoder_layers).to(self.device)\n",
    "        self.decoder = GrafitiDecoderModule(layers[-1], layers=self.decoder_layers).to(self.device)\n",
    "        self.gae = models.GAE(encoder=self.encoder, decoder=self.decoder).to(self.device)\n",
    "        self.optimizer = torch.optim.Adadelta(self.gae.parameters(), lr=lr)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.losses = []\n",
    "        self.global_epoch = 0\n",
    "        self.data = data\n",
    "        print(\"Ready to train!\")\n",
    "\n",
    "    def train(self, epochs, update_interval=5, threshold=0):\n",
    "        prev_loss = 0.\n",
    "        for i in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            z = self.gae.encode(self.data.x, self.data.edge_index, self.data.edge_attr)\n",
    "            reconstruction = self.gae.decode(z, self.data.edge_index, self.data.edge_attr)\n",
    "            loss = self.loss(reconstruction, self.data.x)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.losses.append(loss.item())\n",
    "            if i % update_interval == 0:\n",
    "                print(\"Epoch {} ** iteration {} ** Loss: {}\".format(self.global_epoch, i, np.mean(self.losses[-update_interval:])))\n",
    "            self.global_epoch += 1\n",
    "            curr_loss = loss.item()\n",
    "            if abs(curr_loss - prev_loss) < threshold:\n",
    "                print(\"Minimum threshold!\")\n",
    "                break\n",
    "            prev_loss = curr_loss\n",
    "        print(\"Complete.\")\n",
    "\n",
    "    def __str__(self):\n",
    "        fmt = \"Pytorch Dataset\\n\\n\"\n",
    "        fmt += str(self.data) + \"\\n\\n\"\n",
    "        fmt += \"GAE Architecture\\n\\n\"\n",
    "        fmt += str(self.gae) + \"\\n\"\n",
    "        return fmt\n",
    "\n",
    "    def plot(self):\n",
    "        sns.lineplot(self.losses)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.gae.state_dict(), path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        state_dict = torch.load(path)\n",
    "        self.gae.load_state_dict(state_dict)\n",
    "\n",
    "    def load_embedding(self, adata, encoding_key=\"X_grafiti\"):\n",
    "        with torch.no_grad():\n",
    "            z = self.gae.encode(self.data.x, self.data.edge_index, self.data.edge_attr)\n",
    "            zcpu = z.detach().cpu().numpy()\n",
    "            adata.obsm[encoding_key] = zcpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca301473-e295-40f4-ad0b-33bb965a981e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4839 × 33\n",
       "    obs: 'ClusterName', 'ClusterID', 'Region'\n",
       "    uns: 'ClusterName_colors'\n",
       "    obsm: 'spatial'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad(f'{datadir}/raw/osmfish_remove_excluded.h5ad')\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f367f54-7b91-4703-b2b4-2c8c80323214",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata,radius=50,coord_type='generic',delaunay=True) # Creates spatial_connectivities and spatial_distances in 'obsp' from spatial location (x,y) in 'obsm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42b7c8b-a5c6-4203-a09d-03ed6911c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating PyTorch Geometric Dataset...\n",
      "Setting up Model...\n",
      "Ready to train!\n"
     ]
    }
   ],
   "source": [
    "gae = GAE(adata, layers=[50,50], lr=0.05)#, exponent=2, distance_scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cbfcc7-d862-4fb3-b32a-659c44211faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ** iteration 0 ** Loss: 146747.953125\n",
      "Epoch 1 ** iteration 1 ** Loss: 142217.859375\n",
      "Epoch 2 ** iteration 2 ** Loss: 138062.890625\n",
      "Epoch 3 ** iteration 3 ** Loss: 134319.546875\n",
      "Epoch 4 ** iteration 4 ** Loss: 131118.0625\n",
      "Epoch 5 ** iteration 5 ** Loss: 128108.3046875\n",
      "Epoch 6 ** iteration 6 ** Loss: 125462.140625\n",
      "Epoch 7 ** iteration 7 ** Loss: 123115.3046875\n",
      "Epoch 8 ** iteration 8 ** Loss: 120903.0390625\n",
      "Epoch 9 ** iteration 9 ** Loss: 118987.8984375\n",
      "Epoch 10 ** iteration 10 ** Loss: 117130.9921875\n",
      "Epoch 11 ** iteration 11 ** Loss: 115511.7109375\n",
      "Epoch 12 ** iteration 12 ** Loss: 113958.5859375\n",
      "Epoch 13 ** iteration 13 ** Loss: 112570.5703125\n",
      "Epoch 14 ** iteration 14 ** Loss: 111257.6484375\n",
      "Epoch 15 ** iteration 15 ** Loss: 110059.1953125\n",
      "Epoch 16 ** iteration 16 ** Loss: 108936.875\n",
      "Epoch 17 ** iteration 17 ** Loss: 107905.6484375\n",
      "Epoch 18 ** iteration 18 ** Loss: 106912.5703125\n",
      "Epoch 19 ** iteration 19 ** Loss: 106029.0390625\n",
      "Epoch 20 ** iteration 20 ** Loss: 105178.296875\n",
      "Epoch 21 ** iteration 21 ** Loss: 104389.40625\n",
      "Epoch 22 ** iteration 22 ** Loss: 103657.21875\n",
      "Epoch 23 ** iteration 23 ** Loss: 102977.015625\n",
      "Epoch 24 ** iteration 24 ** Loss: 102360.1171875\n",
      "Epoch 25 ** iteration 25 ** Loss: 101783.21875\n",
      "Epoch 26 ** iteration 26 ** Loss: 101239.5859375\n",
      "Epoch 27 ** iteration 27 ** Loss: 100739.015625\n",
      "Epoch 28 ** iteration 28 ** Loss: 100245.3984375\n",
      "Epoch 29 ** iteration 29 ** Loss: 99799.0390625\n",
      "Epoch 30 ** iteration 30 ** Loss: 99381.8984375\n",
      "Epoch 31 ** iteration 31 ** Loss: 99002.53125\n",
      "Epoch 32 ** iteration 32 ** Loss: 98683.6015625\n",
      "Epoch 33 ** iteration 33 ** Loss: 98390.2109375\n",
      "Epoch 34 ** iteration 34 ** Loss: 98122.1953125\n",
      "Epoch 35 ** iteration 35 ** Loss: 97876.25\n",
      "Epoch 36 ** iteration 36 ** Loss: 97652.8515625\n",
      "Epoch 37 ** iteration 37 ** Loss: 97451.4921875\n",
      "Epoch 38 ** iteration 38 ** Loss: 97271.5859375\n",
      "Epoch 39 ** iteration 39 ** Loss: 97123.234375\n",
      "Epoch 40 ** iteration 40 ** Loss: 96974.7890625\n",
      "Epoch 41 ** iteration 41 ** Loss: 96855.7734375\n",
      "Epoch 42 ** iteration 42 ** Loss: 96757.2578125\n",
      "Epoch 43 ** iteration 43 ** Loss: 96674.953125\n",
      "Epoch 44 ** iteration 44 ** Loss: 96604.4765625\n",
      "Epoch 45 ** iteration 45 ** Loss: 96590.34375\n",
      "Epoch 46 ** iteration 46 ** Loss: 96521.1796875\n",
      "Epoch 47 ** iteration 47 ** Loss: 96481.1953125\n",
      "Epoch 48 ** iteration 48 ** Loss: 96455.2578125\n",
      "Epoch 49 ** iteration 49 ** Loss: 96438.3046875\n",
      "Epoch 50 ** iteration 50 ** Loss: 96424.015625\n",
      "Epoch 51 ** iteration 51 ** Loss: 96414.0703125\n",
      "Epoch 52 ** iteration 52 ** Loss: 96406.2890625\n",
      "Epoch 53 ** iteration 53 ** Loss: 96399.796875\n",
      "Epoch 54 ** iteration 54 ** Loss: 96394.7421875\n",
      "Epoch 55 ** iteration 55 ** Loss: 96391.3828125\n",
      "Epoch 56 ** iteration 56 ** Loss: 96387.625\n",
      "Epoch 57 ** iteration 57 ** Loss: 96387.2265625\n",
      "Epoch 58 ** iteration 58 ** Loss: 96380.7265625\n",
      "Epoch 59 ** iteration 59 ** Loss: 96376.6328125\n",
      "Epoch 60 ** iteration 60 ** Loss: 96374.0234375\n",
      "Epoch 61 ** iteration 61 ** Loss: 96369.8515625\n",
      "Epoch 62 ** iteration 62 ** Loss: 96365.6484375\n",
      "Epoch 63 ** iteration 63 ** Loss: 96361.8203125\n",
      "Epoch 64 ** iteration 64 ** Loss: 96361.03125\n",
      "Epoch 65 ** iteration 65 ** Loss: 96356.6484375\n",
      "Epoch 66 ** iteration 66 ** Loss: 96353.7421875\n",
      "Epoch 67 ** iteration 67 ** Loss: 96350.4375\n",
      "Epoch 68 ** iteration 68 ** Loss: 96343.8359375\n",
      "Epoch 69 ** iteration 69 ** Loss: 96347.0390625\n",
      "Epoch 70 ** iteration 70 ** Loss: 96334.515625\n",
      "Epoch 71 ** iteration 71 ** Loss: 96330.515625\n",
      "Epoch 72 ** iteration 72 ** Loss: 96331.6484375\n",
      "Epoch 73 ** iteration 73 ** Loss: 96325.6015625\n",
      "Epoch 74 ** iteration 74 ** Loss: 96321.0234375\n",
      "Epoch 75 ** iteration 75 ** Loss: 96316.8515625\n",
      "Epoch 76 ** iteration 76 ** Loss: 96311.4609375\n",
      "Epoch 77 ** iteration 77 ** Loss: 96309.28125\n",
      "Epoch 78 ** iteration 78 ** Loss: 96304.203125\n",
      "Epoch 79 ** iteration 79 ** Loss: 96301.9921875\n",
      "Epoch 80 ** iteration 80 ** Loss: 96296.7890625\n",
      "Epoch 81 ** iteration 81 ** Loss: 96291.671875\n",
      "Epoch 82 ** iteration 82 ** Loss: 96288.71875\n",
      "Epoch 83 ** iteration 83 ** Loss: 96289.5546875\n",
      "Epoch 84 ** iteration 84 ** Loss: 96294.609375\n",
      "Epoch 85 ** iteration 85 ** Loss: 96284.1953125\n",
      "Epoch 86 ** iteration 86 ** Loss: 96276.4296875\n",
      "Epoch 87 ** iteration 87 ** Loss: 96267.4296875\n",
      "Epoch 88 ** iteration 88 ** Loss: 96624.140625\n",
      "Epoch 89 ** iteration 89 ** Loss: 96279.7578125\n",
      "Epoch 90 ** iteration 90 ** Loss: 96254.3203125\n",
      "Epoch 91 ** iteration 91 ** Loss: 96246.6640625\n",
      "Epoch 92 ** iteration 92 ** Loss: 96242.828125\n",
      "Epoch 93 ** iteration 93 ** Loss: 96239.1640625\n",
      "Epoch 94 ** iteration 94 ** Loss: 96223.9609375\n",
      "Epoch 95 ** iteration 95 ** Loss: 96210.921875\n",
      "Epoch 96 ** iteration 96 ** Loss: 96196.96875\n",
      "Epoch 97 ** iteration 97 ** Loss: 96188.015625\n",
      "Epoch 98 ** iteration 98 ** Loss: 96361.96875\n",
      "Epoch 99 ** iteration 99 ** Loss: 96169.9453125\n",
      "Epoch 100 ** iteration 100 ** Loss: 96156.375\n",
      "Epoch 101 ** iteration 101 ** Loss: 96146.2421875\n",
      "Epoch 102 ** iteration 102 ** Loss: 96127.109375\n",
      "Epoch 103 ** iteration 103 ** Loss: 96111.71875\n",
      "Epoch 104 ** iteration 104 ** Loss: 96094.390625\n",
      "Epoch 105 ** iteration 105 ** Loss: 96077.515625\n",
      "Epoch 106 ** iteration 106 ** Loss: 96056.6953125\n",
      "Epoch 107 ** iteration 107 ** Loss: 96040.578125\n",
      "Epoch 108 ** iteration 108 ** Loss: 96011.453125\n",
      "Epoch 109 ** iteration 109 ** Loss: 95982.765625\n",
      "Epoch 110 ** iteration 110 ** Loss: 95946.7265625\n",
      "Epoch 111 ** iteration 111 ** Loss: 95899.0859375\n",
      "Epoch 112 ** iteration 112 ** Loss: 95846.7734375\n",
      "Epoch 113 ** iteration 113 ** Loss: 95788.71875\n",
      "Epoch 114 ** iteration 114 ** Loss: 95720.7109375\n",
      "Epoch 115 ** iteration 115 ** Loss: 95640.6015625\n",
      "Epoch 116 ** iteration 116 ** Loss: 95536.84375\n",
      "Epoch 117 ** iteration 117 ** Loss: 95529.4375\n",
      "Epoch 118 ** iteration 118 ** Loss: 95346.125\n",
      "Epoch 119 ** iteration 119 ** Loss: 95180.9375\n",
      "Epoch 120 ** iteration 120 ** Loss: 94985.3828125\n",
      "Epoch 121 ** iteration 121 ** Loss: 94746.71875\n",
      "Epoch 122 ** iteration 122 ** Loss: 94460.515625\n",
      "Epoch 123 ** iteration 123 ** Loss: 94098.9765625\n",
      "Epoch 124 ** iteration 124 ** Loss: 93636.1953125\n",
      "Epoch 125 ** iteration 125 ** Loss: 93074.625\n",
      "Epoch 126 ** iteration 126 ** Loss: 92643.125\n",
      "Epoch 127 ** iteration 127 ** Loss: 91723.5703125\n",
      "Epoch 128 ** iteration 128 ** Loss: 90697.390625\n",
      "Epoch 129 ** iteration 129 ** Loss: 89506.8671875\n",
      "Epoch 130 ** iteration 130 ** Loss: 88142.6328125\n",
      "Epoch 131 ** iteration 131 ** Loss: 86632.390625\n",
      "Epoch 132 ** iteration 132 ** Loss: 84958.1796875\n",
      "Epoch 133 ** iteration 133 ** Loss: 83271.5234375\n",
      "Epoch 134 ** iteration 134 ** Loss: 81784.3359375\n",
      "Epoch 135 ** iteration 135 ** Loss: 80429.5\n",
      "Epoch 136 ** iteration 136 ** Loss: 79339.4375\n",
      "Epoch 137 ** iteration 137 ** Loss: 78489.5\n",
      "Epoch 138 ** iteration 138 ** Loss: 77730.2265625\n",
      "Epoch 139 ** iteration 139 ** Loss: 77114.09375\n",
      "Epoch 140 ** iteration 140 ** Loss: 76608.328125\n",
      "Epoch 141 ** iteration 141 ** Loss: 76202.84375\n",
      "Epoch 142 ** iteration 142 ** Loss: 75881.1015625\n",
      "Epoch 143 ** iteration 143 ** Loss: 75633.484375\n",
      "Epoch 144 ** iteration 144 ** Loss: 75430.0078125\n",
      "Epoch 145 ** iteration 145 ** Loss: 75275.3125\n",
      "Epoch 146 ** iteration 146 ** Loss: 75138.8671875\n",
      "Epoch 147 ** iteration 147 ** Loss: 75034.484375\n",
      "Epoch 148 ** iteration 148 ** Loss: 75038.4296875\n",
      "Epoch 149 ** iteration 149 ** Loss: 74875.7734375\n",
      "Epoch 150 ** iteration 150 ** Loss: 74781.265625\n",
      "Epoch 151 ** iteration 151 ** Loss: 74710.09375\n",
      "Epoch 152 ** iteration 152 ** Loss: 74639.0546875\n",
      "Epoch 153 ** iteration 153 ** Loss: 74576.625\n",
      "Epoch 154 ** iteration 154 ** Loss: 74518.46875\n",
      "Epoch 155 ** iteration 155 ** Loss: 74465.171875\n",
      "Epoch 156 ** iteration 156 ** Loss: 74412.6875\n",
      "Epoch 157 ** iteration 157 ** Loss: 74364.53125\n",
      "Epoch 158 ** iteration 158 ** Loss: 74317.4453125\n",
      "Epoch 159 ** iteration 159 ** Loss: 74274.265625\n",
      "Epoch 160 ** iteration 160 ** Loss: 74229.4609375\n",
      "Epoch 161 ** iteration 161 ** Loss: 74193.6796875\n",
      "Epoch 162 ** iteration 162 ** Loss: 74150.640625\n",
      "Epoch 163 ** iteration 163 ** Loss: 74112.8828125\n",
      "Epoch 164 ** iteration 164 ** Loss: 74078.0859375\n",
      "Epoch 165 ** iteration 165 ** Loss: 74046.03125\n",
      "Epoch 166 ** iteration 166 ** Loss: 74020.2109375\n",
      "Epoch 167 ** iteration 167 ** Loss: 73983.890625\n",
      "Epoch 168 ** iteration 168 ** Loss: 73973.5625\n",
      "Epoch 169 ** iteration 169 ** Loss: 73929.5234375\n",
      "Epoch 170 ** iteration 170 ** Loss: 73901.234375\n",
      "Epoch 171 ** iteration 171 ** Loss: 73874.78125\n",
      "Epoch 172 ** iteration 172 ** Loss: 73848.8203125\n",
      "Epoch 173 ** iteration 173 ** Loss: 73823.96875\n",
      "Epoch 174 ** iteration 174 ** Loss: 73800.1171875\n",
      "Epoch 175 ** iteration 175 ** Loss: 73776.0234375\n",
      "Epoch 176 ** iteration 176 ** Loss: 73753.1171875\n",
      "Epoch 177 ** iteration 177 ** Loss: 73731.4921875\n",
      "Epoch 178 ** iteration 178 ** Loss: 73770.6015625\n",
      "Epoch 179 ** iteration 179 ** Loss: 73704.625\n",
      "Epoch 180 ** iteration 180 ** Loss: 73680.6015625\n",
      "Epoch 181 ** iteration 181 ** Loss: 73660.109375\n",
      "Epoch 182 ** iteration 182 ** Loss: 73640.78125\n",
      "Epoch 183 ** iteration 183 ** Loss: 73620.5234375\n",
      "Epoch 184 ** iteration 184 ** Loss: 73601.1171875\n",
      "Epoch 185 ** iteration 185 ** Loss: 73582.0234375\n",
      "Epoch 186 ** iteration 186 ** Loss: 73563.3125\n",
      "Epoch 187 ** iteration 187 ** Loss: 73545.2890625\n",
      "Epoch 188 ** iteration 188 ** Loss: 73528.234375\n",
      "Epoch 189 ** iteration 189 ** Loss: 73509.09375\n",
      "Epoch 190 ** iteration 190 ** Loss: 73489.765625\n",
      "Epoch 191 ** iteration 191 ** Loss: 73472.1328125\n",
      "Epoch 192 ** iteration 192 ** Loss: 73454.4140625\n",
      "Epoch 193 ** iteration 193 ** Loss: 73438.1015625\n",
      "Epoch 194 ** iteration 194 ** Loss: 73422.4765625\n",
      "Epoch 195 ** iteration 195 ** Loss: 73401.84375\n",
      "Epoch 196 ** iteration 196 ** Loss: 73367.109375\n",
      "Epoch 197 ** iteration 197 ** Loss: 73351.2734375\n",
      "Epoch 198 ** iteration 198 ** Loss: 73341.09375\n",
      "Epoch 199 ** iteration 199 ** Loss: 73311.34375\n",
      "Epoch 200 ** iteration 200 ** Loss: 73295.359375\n",
      "Epoch 201 ** iteration 201 ** Loss: 73288.125\n",
      "Epoch 202 ** iteration 202 ** Loss: 73258.921875\n",
      "Epoch 203 ** iteration 203 ** Loss: 73249.6484375\n",
      "Epoch 204 ** iteration 204 ** Loss: 73230.53125\n",
      "Epoch 205 ** iteration 205 ** Loss: 73207.890625\n",
      "Epoch 206 ** iteration 206 ** Loss: 73193.359375\n",
      "Epoch 207 ** iteration 207 ** Loss: 73184.0390625\n",
      "Epoch 208 ** iteration 208 ** Loss: 73157.7578125\n",
      "Epoch 209 ** iteration 209 ** Loss: 73143.921875\n",
      "Epoch 210 ** iteration 210 ** Loss: 73129.234375\n",
      "Epoch 211 ** iteration 211 ** Loss: 73113.7890625\n",
      "Epoch 212 ** iteration 212 ** Loss: 73099.03125\n",
      "Epoch 213 ** iteration 213 ** Loss: 73086.71875\n",
      "Epoch 214 ** iteration 214 ** Loss: 73070.078125\n",
      "Epoch 215 ** iteration 215 ** Loss: 73057.9453125\n",
      "Epoch 216 ** iteration 216 ** Loss: 73043.53125\n",
      "Epoch 217 ** iteration 217 ** Loss: 73031.546875\n",
      "Epoch 218 ** iteration 218 ** Loss: 73015.6484375\n",
      "Epoch 219 ** iteration 219 ** Loss: 73006.2578125\n",
      "Epoch 220 ** iteration 220 ** Loss: 72989.171875\n",
      "Epoch 221 ** iteration 221 ** Loss: 72978.765625\n",
      "Epoch 222 ** iteration 222 ** Loss: 72963.515625\n",
      "Epoch 223 ** iteration 223 ** Loss: 72953.890625\n",
      "Epoch 224 ** iteration 224 ** Loss: 72939.25\n",
      "Epoch 225 ** iteration 225 ** Loss: 72930.796875\n",
      "Epoch 226 ** iteration 226 ** Loss: 72915.9921875\n",
      "Epoch 227 ** iteration 227 ** Loss: 72907.703125\n",
      "Epoch 228 ** iteration 228 ** Loss: 72893.65625\n",
      "Epoch 229 ** iteration 229 ** Loss: 72886.3828125\n",
      "Epoch 230 ** iteration 230 ** Loss: 72871.8984375\n",
      "Epoch 231 ** iteration 231 ** Loss: 72865.71875\n",
      "Epoch 232 ** iteration 232 ** Loss: 72855.3984375\n",
      "Epoch 233 ** iteration 233 ** Loss: 72846.453125\n",
      "Epoch 234 ** iteration 234 ** Loss: 72829.015625\n",
      "Epoch 235 ** iteration 235 ** Loss: 72820.5859375\n",
      "Epoch 236 ** iteration 236 ** Loss: 72812.3359375\n",
      "Epoch 237 ** iteration 237 ** Loss: 72807.25\n",
      "Epoch 238 ** iteration 238 ** Loss: 72797.1484375\n",
      "Epoch 239 ** iteration 239 ** Loss: 72793.0234375\n",
      "Epoch 240 ** iteration 240 ** Loss: 72781.671875\n",
      "Epoch 241 ** iteration 241 ** Loss: 72785.390625\n",
      "Epoch 242 ** iteration 242 ** Loss: 72764.9375\n",
      "Epoch 243 ** iteration 243 ** Loss: 72756.1484375\n",
      "Epoch 244 ** iteration 244 ** Loss: 72751.4375\n",
      "Epoch 245 ** iteration 245 ** Loss: 72743.71875\n",
      "Epoch 246 ** iteration 246 ** Loss: 72742.75\n",
      "Epoch 247 ** iteration 247 ** Loss: 72727.5234375\n",
      "Epoch 248 ** iteration 248 ** Loss: 72721.3046875\n",
      "Epoch 249 ** iteration 249 ** Loss: 72716.640625\n",
      "Epoch 250 ** iteration 250 ** Loss: 72715.25\n",
      "Epoch 251 ** iteration 251 ** Loss: 72707.21875\n",
      "Epoch 252 ** iteration 252 ** Loss: 72710.296875\n",
      "Epoch 253 ** iteration 253 ** Loss: 72701.8125\n",
      "Epoch 254 ** iteration 254 ** Loss: 72692.3671875\n",
      "Epoch 255 ** iteration 255 ** Loss: 72678.203125\n",
      "Epoch 256 ** iteration 256 ** Loss: 72663.1328125\n",
      "Epoch 257 ** iteration 257 ** Loss: 72647.9140625\n",
      "Epoch 258 ** iteration 258 ** Loss: 72637.375\n",
      "Epoch 259 ** iteration 259 ** Loss: 72635.1796875\n",
      "Epoch 260 ** iteration 260 ** Loss: 72597.75\n",
      "Epoch 261 ** iteration 261 ** Loss: 72601.0625\n",
      "Epoch 262 ** iteration 262 ** Loss: 72569.3203125\n",
      "Epoch 263 ** iteration 263 ** Loss: 72555.84375\n",
      "Epoch 264 ** iteration 264 ** Loss: 72543.3203125\n",
      "Epoch 265 ** iteration 265 ** Loss: 72536.1328125\n",
      "Epoch 266 ** iteration 266 ** Loss: 72528.328125\n",
      "Epoch 267 ** iteration 267 ** Loss: 72511.59375\n",
      "Epoch 268 ** iteration 268 ** Loss: 72497.8203125\n",
      "Epoch 269 ** iteration 269 ** Loss: 72483.5546875\n",
      "Epoch 270 ** iteration 270 ** Loss: 72467.703125\n",
      "Epoch 271 ** iteration 271 ** Loss: 72452.8203125\n",
      "Epoch 272 ** iteration 272 ** Loss: 72441.234375\n",
      "Epoch 273 ** iteration 273 ** Loss: 72428.625\n",
      "Epoch 274 ** iteration 274 ** Loss: 72419.6328125\n",
      "Epoch 275 ** iteration 275 ** Loss: 72406.109375\n",
      "Epoch 276 ** iteration 276 ** Loss: 72396.2421875\n",
      "Epoch 277 ** iteration 277 ** Loss: 72384.75\n",
      "Epoch 278 ** iteration 278 ** Loss: 72375.890625\n",
      "Epoch 279 ** iteration 279 ** Loss: 72364.3203125\n",
      "Epoch 280 ** iteration 280 ** Loss: 72354.8359375\n",
      "Epoch 281 ** iteration 281 ** Loss: 72345.5\n",
      "Epoch 282 ** iteration 282 ** Loss: 72336.5703125\n",
      "Epoch 283 ** iteration 283 ** Loss: 72325.8125\n",
      "Epoch 284 ** iteration 284 ** Loss: 72316.984375\n",
      "Epoch 285 ** iteration 285 ** Loss: 72324.7578125\n",
      "Epoch 286 ** iteration 286 ** Loss: 72306.2421875\n",
      "Epoch 287 ** iteration 287 ** Loss: 72290.6484375\n",
      "Epoch 288 ** iteration 288 ** Loss: 72282.328125\n",
      "Epoch 289 ** iteration 289 ** Loss: 72273.125\n",
      "Epoch 290 ** iteration 290 ** Loss: 72265.0859375\n",
      "Epoch 291 ** iteration 291 ** Loss: 72256.828125\n",
      "Epoch 292 ** iteration 292 ** Loss: 72249.8046875\n",
      "Epoch 293 ** iteration 293 ** Loss: 72241.6484375\n",
      "Epoch 294 ** iteration 294 ** Loss: 72235.0\n",
      "Epoch 295 ** iteration 295 ** Loss: 72227.1640625\n",
      "Epoch 296 ** iteration 296 ** Loss: 72220.6796875\n",
      "Epoch 297 ** iteration 297 ** Loss: 72213.0390625\n",
      "Epoch 298 ** iteration 298 ** Loss: 72207.0859375\n",
      "Epoch 299 ** iteration 299 ** Loss: 72199.8515625\n",
      "Epoch 300 ** iteration 300 ** Loss: 72194.09375\n",
      "Epoch 301 ** iteration 301 ** Loss: 72187.703125\n",
      "Epoch 302 ** iteration 302 ** Loss: 72183.9375\n",
      "Epoch 303 ** iteration 303 ** Loss: 72176.15625\n",
      "Epoch 304 ** iteration 304 ** Loss: 72170.96875\n",
      "Epoch 305 ** iteration 305 ** Loss: 72164.90625\n",
      "Epoch 306 ** iteration 306 ** Loss: 72160.0546875\n",
      "Epoch 307 ** iteration 307 ** Loss: 72154.671875\n",
      "Epoch 308 ** iteration 308 ** Loss: 72155.3203125\n",
      "Epoch 309 ** iteration 309 ** Loss: 72144.859375\n",
      "Epoch 310 ** iteration 310 ** Loss: 72140.4140625\n",
      "Epoch 311 ** iteration 311 ** Loss: 72135.3046875\n",
      "Epoch 312 ** iteration 312 ** Loss: 72130.609375\n",
      "Epoch 313 ** iteration 313 ** Loss: 72126.078125\n",
      "Epoch 314 ** iteration 314 ** Loss: 72122.0703125\n",
      "Epoch 315 ** iteration 315 ** Loss: 72118.0078125\n",
      "Epoch 316 ** iteration 316 ** Loss: 72115.3046875\n",
      "Epoch 317 ** iteration 317 ** Loss: 72108.640625\n",
      "Epoch 318 ** iteration 318 ** Loss: 72108.25\n",
      "Epoch 319 ** iteration 319 ** Loss: 72103.3203125\n",
      "Epoch 320 ** iteration 320 ** Loss: 72100.09375\n",
      "Epoch 321 ** iteration 321 ** Loss: 72096.9375\n",
      "Epoch 322 ** iteration 322 ** Loss: 72093.453125\n",
      "Epoch 323 ** iteration 323 ** Loss: 72091.5703125\n",
      "Epoch 324 ** iteration 324 ** Loss: 72087.7890625\n",
      "Epoch 325 ** iteration 325 ** Loss: 72085.5703125\n",
      "Epoch 326 ** iteration 326 ** Loss: 72081.671875\n",
      "Epoch 327 ** iteration 327 ** Loss: 72079.1875\n",
      "Epoch 328 ** iteration 328 ** Loss: 72076.4921875\n",
      "Epoch 329 ** iteration 329 ** Loss: 72074.9921875\n",
      "Epoch 330 ** iteration 330 ** Loss: 72071.484375\n",
      "Epoch 331 ** iteration 331 ** Loss: 72069.0234375\n",
      "Epoch 332 ** iteration 332 ** Loss: 72066.6171875\n",
      "Epoch 333 ** iteration 333 ** Loss: 72065.265625\n",
      "Epoch 334 ** iteration 334 ** Loss: 72062.78125\n",
      "Epoch 335 ** iteration 335 ** Loss: 72061.3515625\n",
      "Epoch 336 ** iteration 336 ** Loss: 72059.25\n",
      "Epoch 337 ** iteration 337 ** Loss: 72058.8984375\n",
      "Epoch 338 ** iteration 338 ** Loss: 72055.34375\n",
      "Epoch 339 ** iteration 339 ** Loss: 72053.7890625\n",
      "Epoch 340 ** iteration 340 ** Loss: 72051.2109375\n",
      "Epoch 341 ** iteration 341 ** Loss: 72049.6796875\n",
      "Epoch 342 ** iteration 342 ** Loss: 72048.09375\n",
      "Epoch 343 ** iteration 343 ** Loss: 72047.1953125\n",
      "Epoch 344 ** iteration 344 ** Loss: 72044.9609375\n",
      "Epoch 345 ** iteration 345 ** Loss: 72043.375\n",
      "Epoch 346 ** iteration 346 ** Loss: 72041.6328125\n",
      "Epoch 347 ** iteration 347 ** Loss: 72041.2734375\n",
      "Epoch 348 ** iteration 348 ** Loss: 72038.9921875\n",
      "Epoch 349 ** iteration 349 ** Loss: 72037.984375\n",
      "Epoch 350 ** iteration 350 ** Loss: 72036.0\n",
      "Epoch 351 ** iteration 351 ** Loss: 72035.078125\n",
      "Epoch 352 ** iteration 352 ** Loss: 72033.6640625\n",
      "Epoch 353 ** iteration 353 ** Loss: 72033.46875\n",
      "Epoch 354 ** iteration 354 ** Loss: 72031.625\n",
      "Epoch 355 ** iteration 355 ** Loss: 72030.8671875\n",
      "Epoch 356 ** iteration 356 ** Loss: 72029.046875\n",
      "Epoch 357 ** iteration 357 ** Loss: 72248.390625\n",
      "Epoch 358 ** iteration 358 ** Loss: 72035.8203125\n",
      "Epoch 359 ** iteration 359 ** Loss: 72027.4453125\n",
      "Epoch 360 ** iteration 360 ** Loss: 72025.3515625\n",
      "Epoch 361 ** iteration 361 ** Loss: 72023.90625\n",
      "Epoch 362 ** iteration 362 ** Loss: 72022.7578125\n",
      "Epoch 363 ** iteration 363 ** Loss: 72045.09375\n",
      "Epoch 364 ** iteration 364 ** Loss: 72019.6640625\n",
      "Epoch 365 ** iteration 365 ** Loss: 72051.7734375\n",
      "Epoch 366 ** iteration 366 ** Loss: 72019.140625\n",
      "Epoch 367 ** iteration 367 ** Loss: 72017.7421875\n",
      "Epoch 368 ** iteration 368 ** Loss: 72017.2109375\n",
      "Epoch 369 ** iteration 369 ** Loss: 72016.203125\n",
      "Epoch 370 ** iteration 370 ** Loss: 72015.3125\n",
      "Epoch 371 ** iteration 371 ** Loss: 72110.2734375\n",
      "Epoch 372 ** iteration 372 ** Loss: 72019.3671875\n",
      "Epoch 373 ** iteration 373 ** Loss: 72015.1953125\n",
      "Epoch 374 ** iteration 374 ** Loss: 72013.84375\n",
      "Epoch 375 ** iteration 375 ** Loss: 72013.390625\n",
      "Epoch 376 ** iteration 376 ** Loss: 72011.796875\n",
      "Epoch 377 ** iteration 377 ** Loss: 72010.8671875\n",
      "Epoch 378 ** iteration 378 ** Loss: 72010.0390625\n",
      "Epoch 379 ** iteration 379 ** Loss: 72009.1875\n",
      "Epoch 380 ** iteration 380 ** Loss: 72008.4296875\n",
      "Epoch 381 ** iteration 381 ** Loss: 72007.5859375\n",
      "Epoch 382 ** iteration 382 ** Loss: 72006.8671875\n",
      "Epoch 383 ** iteration 383 ** Loss: 72005.96875\n",
      "Epoch 384 ** iteration 384 ** Loss: 72005.1640625\n",
      "Epoch 385 ** iteration 385 ** Loss: 72004.3671875\n",
      "Epoch 386 ** iteration 386 ** Loss: 72003.6015625\n",
      "Epoch 387 ** iteration 387 ** Loss: 72002.78125\n",
      "Epoch 388 ** iteration 388 ** Loss: 72002.078125\n",
      "Epoch 389 ** iteration 389 ** Loss: 72001.203125\n",
      "Epoch 390 ** iteration 390 ** Loss: 72000.4609375\n",
      "Epoch 391 ** iteration 391 ** Loss: 71999.6171875\n",
      "Epoch 392 ** iteration 392 ** Loss: 71998.8125\n",
      "Epoch 393 ** iteration 393 ** Loss: 71997.984375\n",
      "Epoch 394 ** iteration 394 ** Loss: 71997.234375\n",
      "Epoch 395 ** iteration 395 ** Loss: 71996.421875\n",
      "Epoch 396 ** iteration 396 ** Loss: 71995.6875\n",
      "Epoch 397 ** iteration 397 ** Loss: 71994.796875\n",
      "Epoch 398 ** iteration 398 ** Loss: 71994.1171875\n",
      "Epoch 399 ** iteration 399 ** Loss: 71993.21875\n",
      "Epoch 400 ** iteration 400 ** Loss: 71992.4375\n",
      "Epoch 401 ** iteration 401 ** Loss: 71991.6171875\n",
      "Epoch 402 ** iteration 402 ** Loss: 71990.828125\n",
      "Epoch 403 ** iteration 403 ** Loss: 71989.9296875\n",
      "Epoch 404 ** iteration 404 ** Loss: 71989.1484375\n",
      "Epoch 405 ** iteration 405 ** Loss: 71988.234375\n",
      "Epoch 406 ** iteration 406 ** Loss: 71987.4609375\n",
      "Epoch 407 ** iteration 407 ** Loss: 71986.59375\n",
      "Epoch 408 ** iteration 408 ** Loss: 71985.828125\n",
      "Epoch 409 ** iteration 409 ** Loss: 71984.921875\n",
      "Epoch 410 ** iteration 410 ** Loss: 71984.1328125\n",
      "Epoch 411 ** iteration 411 ** Loss: 71987.7265625\n",
      "Epoch 412 ** iteration 412 ** Loss: 71982.921875\n",
      "Epoch 413 ** iteration 413 ** Loss: 71981.84375\n",
      "Epoch 414 ** iteration 414 ** Loss: 71981.2109375\n",
      "Epoch 415 ** iteration 415 ** Loss: 71980.3046875\n",
      "Epoch 416 ** iteration 416 ** Loss: 71979.53125\n",
      "Epoch 417 ** iteration 417 ** Loss: 71978.71875\n",
      "Epoch 418 ** iteration 418 ** Loss: 71978.140625\n",
      "Epoch 419 ** iteration 419 ** Loss: 71977.109375\n",
      "Epoch 420 ** iteration 420 ** Loss: 71976.296875\n",
      "Epoch 421 ** iteration 421 ** Loss: 71975.46875\n",
      "Epoch 422 ** iteration 422 ** Loss: 71974.8046875\n",
      "Epoch 423 ** iteration 423 ** Loss: 71973.9375\n",
      "Epoch 424 ** iteration 424 ** Loss: 71973.15625\n",
      "Epoch 425 ** iteration 425 ** Loss: 71972.2578125\n",
      "Epoch 426 ** iteration 426 ** Loss: 71968.890625\n",
      "Epoch 427 ** iteration 427 ** Loss: 71966.9609375\n",
      "Epoch 428 ** iteration 428 ** Loss: 71965.734375\n",
      "Epoch 429 ** iteration 429 ** Loss: 71964.328125\n",
      "Epoch 430 ** iteration 430 ** Loss: 71963.3828125\n",
      "Epoch 431 ** iteration 431 ** Loss: 72012.1328125\n",
      "Epoch 432 ** iteration 432 ** Loss: 71963.15625\n",
      "Epoch 433 ** iteration 433 ** Loss: 524860.75\n",
      "Epoch 434 ** iteration 434 ** Loss: 71967.6796875\n",
      "Epoch 435 ** iteration 435 ** Loss: 71963.5703125\n",
      "Epoch 436 ** iteration 436 ** Loss: 71961.6875\n",
      "Epoch 437 ** iteration 437 ** Loss: 71960.28125\n",
      "Epoch 438 ** iteration 438 ** Loss: 71959.2265625\n",
      "Epoch 439 ** iteration 439 ** Loss: 71958.265625\n",
      "Epoch 440 ** iteration 440 ** Loss: 71957.4296875\n",
      "Epoch 441 ** iteration 441 ** Loss: 71956.6796875\n",
      "Epoch 442 ** iteration 442 ** Loss: 71955.9140625\n",
      "Epoch 443 ** iteration 443 ** Loss: 71955.1875\n",
      "Epoch 444 ** iteration 444 ** Loss: 71954.46875\n",
      "Epoch 445 ** iteration 445 ** Loss: 71953.7578125\n",
      "Epoch 446 ** iteration 446 ** Loss: 71953.015625\n",
      "Epoch 447 ** iteration 447 ** Loss: 71952.359375\n",
      "Epoch 448 ** iteration 448 ** Loss: 71951.6484375\n",
      "Epoch 449 ** iteration 449 ** Loss: 71950.9921875\n",
      "Epoch 450 ** iteration 450 ** Loss: 71950.265625\n",
      "Epoch 451 ** iteration 451 ** Loss: 71949.671875\n",
      "Epoch 452 ** iteration 452 ** Loss: 71948.8671875\n",
      "Epoch 453 ** iteration 453 ** Loss: 71948.1875\n",
      "Epoch 454 ** iteration 454 ** Loss: 71947.453125\n",
      "Epoch 455 ** iteration 455 ** Loss: 71946.765625\n",
      "Epoch 456 ** iteration 456 ** Loss: 71945.9921875\n",
      "Epoch 457 ** iteration 457 ** Loss: 71942.625\n",
      "Epoch 458 ** iteration 458 ** Loss: 71919.0625\n",
      "Epoch 459 ** iteration 459 ** Loss: 71895.5\n",
      "Epoch 460 ** iteration 460 ** Loss: 71872.4296875\n",
      "Epoch 461 ** iteration 461 ** Loss: 71849.84375\n",
      "Epoch 462 ** iteration 462 ** Loss: 71827.7265625\n",
      "Epoch 463 ** iteration 463 ** Loss: 71806.4296875\n",
      "Epoch 464 ** iteration 464 ** Loss: 71785.703125\n",
      "Epoch 465 ** iteration 465 ** Loss: 71765.640625\n",
      "Epoch 466 ** iteration 466 ** Loss: 71746.09375\n",
      "Epoch 467 ** iteration 467 ** Loss: 71727.0546875\n",
      "Epoch 468 ** iteration 468 ** Loss: 71708.5390625\n",
      "Epoch 469 ** iteration 469 ** Loss: 71690.5234375\n",
      "Epoch 470 ** iteration 470 ** Loss: 71673.015625\n",
      "Epoch 471 ** iteration 471 ** Loss: 71656.015625\n",
      "Epoch 472 ** iteration 472 ** Loss: 71639.3671875\n",
      "Epoch 473 ** iteration 473 ** Loss: 71623.234375\n",
      "Epoch 474 ** iteration 474 ** Loss: 71607.53125\n",
      "Epoch 475 ** iteration 475 ** Loss: 71592.2890625\n",
      "Epoch 476 ** iteration 476 ** Loss: 71577.328125\n",
      "Epoch 477 ** iteration 477 ** Loss: 71562.9453125\n",
      "Epoch 478 ** iteration 478 ** Loss: 71548.734375\n",
      "Epoch 479 ** iteration 479 ** Loss: 71534.96875\n",
      "Epoch 480 ** iteration 480 ** Loss: 71521.5546875\n",
      "Epoch 481 ** iteration 481 ** Loss: 71508.546875\n",
      "Epoch 482 ** iteration 482 ** Loss: 71495.8984375\n",
      "Epoch 483 ** iteration 483 ** Loss: 71483.6015625\n",
      "Epoch 484 ** iteration 484 ** Loss: 71471.578125\n",
      "Epoch 485 ** iteration 485 ** Loss: 71459.84375\n",
      "Epoch 486 ** iteration 486 ** Loss: 71448.2734375\n",
      "Epoch 487 ** iteration 487 ** Loss: 71437.234375\n",
      "Epoch 488 ** iteration 488 ** Loss: 71426.421875\n",
      "Epoch 489 ** iteration 489 ** Loss: 71416.0234375\n",
      "Epoch 490 ** iteration 490 ** Loss: 71405.84375\n",
      "Epoch 491 ** iteration 491 ** Loss: 71396.078125\n",
      "Epoch 492 ** iteration 492 ** Loss: 71386.3046875\n",
      "Epoch 493 ** iteration 493 ** Loss: 71376.953125\n",
      "Epoch 494 ** iteration 494 ** Loss: 71367.875\n",
      "Epoch 495 ** iteration 495 ** Loss: 71362.1171875\n",
      "Epoch 496 ** iteration 496 ** Loss: 71350.6640625\n",
      "Epoch 497 ** iteration 497 ** Loss: 71342.1640625\n",
      "Epoch 498 ** iteration 498 ** Loss: 71333.84375\n",
      "Epoch 499 ** iteration 499 ** Loss: 71325.96875\n",
      "Epoch 500 ** iteration 500 ** Loss: 71318.296875\n",
      "Epoch 501 ** iteration 501 ** Loss: 71310.84375\n",
      "Epoch 502 ** iteration 502 ** Loss: 71303.59375\n",
      "Epoch 503 ** iteration 503 ** Loss: 71296.5\n",
      "Epoch 504 ** iteration 504 ** Loss: 71289.390625\n",
      "Epoch 505 ** iteration 505 ** Loss: 71282.6875\n",
      "Epoch 506 ** iteration 506 ** Loss: 71276.1796875\n",
      "Epoch 507 ** iteration 507 ** Loss: 71269.9609375\n",
      "Epoch 508 ** iteration 508 ** Loss: 71263.7421875\n",
      "Epoch 509 ** iteration 509 ** Loss: 71257.515625\n",
      "Epoch 510 ** iteration 510 ** Loss: 71251.59375\n",
      "Epoch 511 ** iteration 511 ** Loss: 71245.9765625\n",
      "Epoch 512 ** iteration 512 ** Loss: 71240.609375\n",
      "Epoch 513 ** iteration 513 ** Loss: 71235.5078125\n",
      "Epoch 514 ** iteration 514 ** Loss: 71230.2421875\n",
      "Epoch 515 ** iteration 515 ** Loss: 71224.9453125\n",
      "Epoch 516 ** iteration 516 ** Loss: 71219.9375\n",
      "Epoch 517 ** iteration 517 ** Loss: 71214.8515625\n",
      "Epoch 518 ** iteration 518 ** Loss: 71209.8203125\n",
      "Epoch 519 ** iteration 519 ** Loss: 71205.2109375\n",
      "Epoch 520 ** iteration 520 ** Loss: 71200.6875\n",
      "Epoch 521 ** iteration 521 ** Loss: 71196.09375\n",
      "Epoch 522 ** iteration 522 ** Loss: 71191.7421875\n",
      "Epoch 523 ** iteration 523 ** Loss: 71187.6171875\n",
      "Epoch 524 ** iteration 524 ** Loss: 71183.5078125\n",
      "Epoch 525 ** iteration 525 ** Loss: 71179.7265625\n",
      "Epoch 526 ** iteration 526 ** Loss: 71175.8125\n",
      "Epoch 527 ** iteration 527 ** Loss: 71172.140625\n",
      "Epoch 528 ** iteration 528 ** Loss: 71169.65625\n",
      "Epoch 529 ** iteration 529 ** Loss: 71165.796875\n",
      "Epoch 530 ** iteration 530 ** Loss: 71161.609375\n",
      "Epoch 531 ** iteration 531 ** Loss: 71158.046875\n",
      "Epoch 532 ** iteration 532 ** Loss: 71154.6796875\n",
      "Epoch 533 ** iteration 533 ** Loss: 71151.4296875\n",
      "Epoch 534 ** iteration 534 ** Loss: 71148.234375\n",
      "Epoch 535 ** iteration 535 ** Loss: 71145.1875\n",
      "Epoch 536 ** iteration 536 ** Loss: 71142.2578125\n",
      "Epoch 537 ** iteration 537 ** Loss: 71139.4609375\n",
      "Epoch 538 ** iteration 538 ** Loss: 71136.6953125\n",
      "Epoch 539 ** iteration 539 ** Loss: 71134.03125\n",
      "Epoch 540 ** iteration 540 ** Loss: 71131.15625\n",
      "Epoch 541 ** iteration 541 ** Loss: 71128.5078125\n",
      "Epoch 542 ** iteration 542 ** Loss: 71125.828125\n",
      "Epoch 543 ** iteration 543 ** Loss: 71123.421875\n",
      "Epoch 544 ** iteration 544 ** Loss: 71120.9296875\n",
      "Epoch 545 ** iteration 545 ** Loss: 71118.5859375\n",
      "Epoch 546 ** iteration 546 ** Loss: 71116.0859375\n",
      "Epoch 547 ** iteration 547 ** Loss: 71114.0390625\n",
      "Epoch 548 ** iteration 548 ** Loss: 71112.1875\n",
      "Epoch 549 ** iteration 549 ** Loss: 71109.8125\n",
      "Epoch 550 ** iteration 550 ** Loss: 71114.4765625\n",
      "Epoch 551 ** iteration 551 ** Loss: 71103.8046875\n",
      "Epoch 552 ** iteration 552 ** Loss: 71101.34375\n",
      "Epoch 553 ** iteration 553 ** Loss: 71099.1796875\n",
      "Epoch 554 ** iteration 554 ** Loss: 71097.1640625\n",
      "Epoch 555 ** iteration 555 ** Loss: 71095.265625\n",
      "Epoch 556 ** iteration 556 ** Loss: 71093.4609375\n",
      "Epoch 557 ** iteration 557 ** Loss: 71091.3671875\n",
      "Epoch 558 ** iteration 558 ** Loss: 71089.21875\n",
      "Epoch 559 ** iteration 559 ** Loss: 71087.359375\n",
      "Epoch 560 ** iteration 560 ** Loss: 71085.6015625\n",
      "Epoch 561 ** iteration 561 ** Loss: 71083.9921875\n",
      "Epoch 562 ** iteration 562 ** Loss: 71082.1953125\n",
      "Epoch 563 ** iteration 563 ** Loss: 71080.5859375\n",
      "Epoch 564 ** iteration 564 ** Loss: 71079.6484375\n",
      "Epoch 565 ** iteration 565 ** Loss: 71076.859375\n",
      "Epoch 566 ** iteration 566 ** Loss: 71077.8046875\n",
      "Epoch 567 ** iteration 567 ** Loss: 71073.515625\n",
      "Epoch 568 ** iteration 568 ** Loss: 71071.7265625\n",
      "Epoch 569 ** iteration 569 ** Loss: 71070.234375\n",
      "Epoch 570 ** iteration 570 ** Loss: 71068.6484375\n",
      "Epoch 571 ** iteration 571 ** Loss: 71067.421875\n",
      "Epoch 572 ** iteration 572 ** Loss: 71066.203125\n",
      "Epoch 573 ** iteration 573 ** Loss: 71064.1015625\n",
      "Epoch 574 ** iteration 574 ** Loss: 71062.0703125\n",
      "Epoch 575 ** iteration 575 ** Loss: 71060.390625\n",
      "Epoch 576 ** iteration 576 ** Loss: 71058.8515625\n",
      "Epoch 577 ** iteration 577 ** Loss: 71057.0546875\n",
      "Epoch 578 ** iteration 578 ** Loss: 71055.4296875\n",
      "Epoch 579 ** iteration 579 ** Loss: 71053.96875\n",
      "Epoch 580 ** iteration 580 ** Loss: 71052.4453125\n",
      "Epoch 581 ** iteration 581 ** Loss: 71051.1484375\n",
      "Epoch 582 ** iteration 582 ** Loss: 71049.78125\n",
      "Epoch 583 ** iteration 583 ** Loss: 71047.9609375\n",
      "Epoch 584 ** iteration 584 ** Loss: 71046.265625\n",
      "Epoch 585 ** iteration 585 ** Loss: 71044.8046875\n",
      "Epoch 586 ** iteration 586 ** Loss: 71043.2890625\n",
      "Epoch 587 ** iteration 587 ** Loss: 71042.0078125\n",
      "Epoch 588 ** iteration 588 ** Loss: 71040.4140625\n",
      "Epoch 589 ** iteration 589 ** Loss: 71039.09375\n",
      "Epoch 590 ** iteration 590 ** Loss: 71035.390625\n",
      "Epoch 591 ** iteration 591 ** Loss: 70999.328125\n",
      "Epoch 592 ** iteration 592 ** Loss: 70962.6015625\n",
      "Epoch 593 ** iteration 593 ** Loss: 70926.828125\n",
      "Epoch 594 ** iteration 594 ** Loss: 70891.796875\n",
      "Epoch 595 ** iteration 595 ** Loss: 70858.3828125\n",
      "Epoch 596 ** iteration 596 ** Loss: 70824.4765625\n",
      "Epoch 597 ** iteration 597 ** Loss: 70791.2734375\n",
      "Epoch 598 ** iteration 598 ** Loss: 70759.125\n",
      "Epoch 599 ** iteration 599 ** Loss: 70728.015625\n",
      "Epoch 600 ** iteration 600 ** Loss: 70697.578125\n",
      "Epoch 601 ** iteration 601 ** Loss: 70667.9609375\n",
      "Epoch 602 ** iteration 602 ** Loss: 70638.8671875\n",
      "Epoch 603 ** iteration 603 ** Loss: 70611.0546875\n",
      "Epoch 604 ** iteration 604 ** Loss: 70583.546875\n",
      "Epoch 605 ** iteration 605 ** Loss: 70556.9921875\n",
      "Epoch 606 ** iteration 606 ** Loss: 70530.671875\n",
      "Epoch 607 ** iteration 607 ** Loss: 70505.3515625\n",
      "Epoch 608 ** iteration 608 ** Loss: 70480.0234375\n",
      "Epoch 609 ** iteration 609 ** Loss: 70456.234375\n",
      "Epoch 610 ** iteration 610 ** Loss: 70432.9296875\n",
      "Epoch 611 ** iteration 611 ** Loss: 70410.0390625\n",
      "Epoch 612 ** iteration 612 ** Loss: 70387.609375\n",
      "Epoch 613 ** iteration 613 ** Loss: 70363.546875\n",
      "Epoch 614 ** iteration 614 ** Loss: 71023.5\n",
      "Epoch 615 ** iteration 615 ** Loss: 70328.8828125\n",
      "Epoch 616 ** iteration 616 ** Loss: 70303.0859375\n",
      "Epoch 617 ** iteration 617 ** Loss: 70281.2578125\n",
      "Epoch 618 ** iteration 618 ** Loss: 70261.7109375\n",
      "Epoch 619 ** iteration 619 ** Loss: 70243.1328125\n",
      "Epoch 620 ** iteration 620 ** Loss: 70225.203125\n",
      "Epoch 621 ** iteration 621 ** Loss: 70207.671875\n",
      "Epoch 622 ** iteration 622 ** Loss: 70190.3359375\n",
      "Epoch 623 ** iteration 623 ** Loss: 70173.7578125\n",
      "Epoch 624 ** iteration 624 ** Loss: 70158.2734375\n",
      "Epoch 625 ** iteration 625 ** Loss: 70145.7421875\n",
      "Epoch 626 ** iteration 626 ** Loss: 70127.40625\n",
      "Epoch 627 ** iteration 627 ** Loss: 70112.1484375\n",
      "Epoch 628 ** iteration 628 ** Loss: 70097.625\n",
      "Epoch 629 ** iteration 629 ** Loss: 70083.5234375\n",
      "Epoch 630 ** iteration 630 ** Loss: 70069.8125\n",
      "Epoch 631 ** iteration 631 ** Loss: 70056.71875\n",
      "Epoch 632 ** iteration 632 ** Loss: 70044.2265625\n",
      "Epoch 633 ** iteration 633 ** Loss: 70031.7578125\n",
      "Epoch 634 ** iteration 634 ** Loss: 70019.203125\n",
      "Epoch 635 ** iteration 635 ** Loss: 70007.4921875\n",
      "Epoch 636 ** iteration 636 ** Loss: 69995.96875\n",
      "Epoch 637 ** iteration 637 ** Loss: 69985.1796875\n",
      "Epoch 638 ** iteration 638 ** Loss: 69974.4296875\n",
      "Epoch 639 ** iteration 639 ** Loss: 69964.3671875\n",
      "Epoch 640 ** iteration 640 ** Loss: 69953.828125\n",
      "Epoch 641 ** iteration 641 ** Loss: 69943.703125\n",
      "Epoch 642 ** iteration 642 ** Loss: 69934.1640625\n",
      "Epoch 643 ** iteration 643 ** Loss: 69925.71875\n",
      "Epoch 644 ** iteration 644 ** Loss: 69916.0234375\n",
      "Epoch 645 ** iteration 645 ** Loss: 69907.2890625\n",
      "Epoch 646 ** iteration 646 ** Loss: 69898.6796875\n",
      "Epoch 647 ** iteration 647 ** Loss: 69890.46875\n",
      "Epoch 648 ** iteration 648 ** Loss: 69882.0625\n",
      "Epoch 649 ** iteration 649 ** Loss: 69875.7265625\n",
      "Epoch 650 ** iteration 650 ** Loss: 69868.5546875\n",
      "Epoch 651 ** iteration 651 ** Loss: 69860.953125\n",
      "Epoch 652 ** iteration 652 ** Loss: 69854.1796875\n",
      "Epoch 653 ** iteration 653 ** Loss: 69847.921875\n",
      "Epoch 654 ** iteration 654 ** Loss: 69840.71875\n",
      "Epoch 655 ** iteration 655 ** Loss: 69834.421875\n",
      "Epoch 656 ** iteration 656 ** Loss: 69828.4609375\n",
      "Epoch 657 ** iteration 657 ** Loss: 69822.1875\n",
      "Epoch 658 ** iteration 658 ** Loss: 69815.96875\n",
      "Epoch 659 ** iteration 659 ** Loss: 69814.3671875\n",
      "Epoch 660 ** iteration 660 ** Loss: 69806.625\n",
      "Epoch 661 ** iteration 661 ** Loss: 69799.21875\n",
      "Epoch 662 ** iteration 662 ** Loss: 69793.234375\n",
      "Epoch 663 ** iteration 663 ** Loss: 69787.3359375\n",
      "Epoch 664 ** iteration 664 ** Loss: 69781.75\n",
      "Epoch 665 ** iteration 665 ** Loss: 69776.3515625\n",
      "Epoch 666 ** iteration 666 ** Loss: 69771.1328125\n",
      "Epoch 667 ** iteration 667 ** Loss: 69766.2265625\n",
      "Epoch 668 ** iteration 668 ** Loss: 69761.0703125\n",
      "Epoch 669 ** iteration 669 ** Loss: 70304.203125\n",
      "Epoch 670 ** iteration 670 ** Loss: 69754.7265625\n",
      "Epoch 671 ** iteration 671 ** Loss: 69745.984375\n",
      "Epoch 672 ** iteration 672 ** Loss: 69740.796875\n",
      "Epoch 673 ** iteration 673 ** Loss: 69736.4921875\n",
      "Epoch 674 ** iteration 674 ** Loss: 69732.015625\n",
      "Epoch 675 ** iteration 675 ** Loss: 69727.78125\n",
      "Epoch 676 ** iteration 676 ** Loss: 69723.7265625\n",
      "Epoch 677 ** iteration 677 ** Loss: 69719.84375\n",
      "Epoch 678 ** iteration 678 ** Loss: 69715.8125\n",
      "Epoch 679 ** iteration 679 ** Loss: 69711.921875\n",
      "Epoch 680 ** iteration 680 ** Loss: 69708.2421875\n",
      "Epoch 681 ** iteration 681 ** Loss: 69704.8984375\n",
      "Epoch 682 ** iteration 682 ** Loss: 69700.9375\n",
      "Epoch 683 ** iteration 683 ** Loss: 69697.2421875\n",
      "Epoch 684 ** iteration 684 ** Loss: 69693.9375\n",
      "Epoch 685 ** iteration 685 ** Loss: 69690.90625\n",
      "Epoch 686 ** iteration 686 ** Loss: 69687.1015625\n",
      "Epoch 687 ** iteration 687 ** Loss: 69683.3671875\n",
      "Epoch 688 ** iteration 688 ** Loss: 69680.1328125\n",
      "Epoch 689 ** iteration 689 ** Loss: 69676.9609375\n",
      "Epoch 690 ** iteration 690 ** Loss: 69673.953125\n",
      "Epoch 691 ** iteration 691 ** Loss: 69670.1796875\n",
      "Epoch 692 ** iteration 692 ** Loss: 69666.921875\n",
      "Epoch 693 ** iteration 693 ** Loss: 69665.0078125\n",
      "Epoch 694 ** iteration 694 ** Loss: 69662.9921875\n",
      "Epoch 695 ** iteration 695 ** Loss: 69658.46875\n",
      "Epoch 696 ** iteration 696 ** Loss: 69654.6640625\n",
      "Epoch 697 ** iteration 697 ** Loss: 69651.1796875\n",
      "Epoch 698 ** iteration 698 ** Loss: 69648.828125\n",
      "Epoch 699 ** iteration 699 ** Loss: 69646.8828125\n",
      "Epoch 700 ** iteration 700 ** Loss: 69642.8125\n",
      "Epoch 701 ** iteration 701 ** Loss: 69639.0546875\n",
      "Epoch 702 ** iteration 702 ** Loss: 69635.96875\n",
      "Epoch 703 ** iteration 703 ** Loss: 69633.078125\n",
      "Epoch 704 ** iteration 704 ** Loss: 69630.3515625\n",
      "Epoch 705 ** iteration 705 ** Loss: 69626.890625\n",
      "Epoch 706 ** iteration 706 ** Loss: 69624.0625\n",
      "Epoch 707 ** iteration 707 ** Loss: 69620.875\n",
      "Epoch 708 ** iteration 708 ** Loss: 69618.1796875\n",
      "Epoch 709 ** iteration 709 ** Loss: 69615.2890625\n",
      "Epoch 710 ** iteration 710 ** Loss: 69613.8515625\n",
      "Epoch 711 ** iteration 711 ** Loss: 69609.1875\n",
      "Epoch 712 ** iteration 712 ** Loss: 69606.3515625\n",
      "Epoch 713 ** iteration 713 ** Loss: 69605.25\n",
      "Epoch 714 ** iteration 714 ** Loss: 69604.2265625\n",
      "Epoch 715 ** iteration 715 ** Loss: 69600.21875\n",
      "Epoch 716 ** iteration 716 ** Loss: 69596.515625\n",
      "Epoch 717 ** iteration 717 ** Loss: 69593.078125\n",
      "Epoch 718 ** iteration 718 ** Loss: 69589.9140625\n",
      "Epoch 719 ** iteration 719 ** Loss: 69586.9296875\n",
      "Epoch 720 ** iteration 720 ** Loss: 69584.0390625\n",
      "Epoch 721 ** iteration 721 ** Loss: 69580.734375\n",
      "Epoch 722 ** iteration 722 ** Loss: 69577.5625\n",
      "Epoch 723 ** iteration 723 ** Loss: 69573.8046875\n",
      "Epoch 724 ** iteration 724 ** Loss: 69570.7890625\n",
      "Epoch 725 ** iteration 725 ** Loss: 69567.0078125\n",
      "Epoch 726 ** iteration 726 ** Loss: 69563.859375\n",
      "Epoch 727 ** iteration 727 ** Loss: 69560.359375\n",
      "Epoch 728 ** iteration 728 ** Loss: 69556.7734375\n",
      "Epoch 729 ** iteration 729 ** Loss: 69552.8125\n",
      "Epoch 730 ** iteration 730 ** Loss: 69548.8984375\n",
      "Epoch 731 ** iteration 731 ** Loss: 69560.9609375\n",
      "Epoch 732 ** iteration 732 ** Loss: 69541.5703125\n",
      "Epoch 733 ** iteration 733 ** Loss: 69541.40625\n",
      "Epoch 734 ** iteration 734 ** Loss: 69535.0390625\n",
      "Epoch 735 ** iteration 735 ** Loss: 69530.6953125\n",
      "Epoch 736 ** iteration 736 ** Loss: 69527.28125\n",
      "Epoch 737 ** iteration 737 ** Loss: 69523.1796875\n",
      "Epoch 738 ** iteration 738 ** Loss: 69519.3046875\n",
      "Epoch 739 ** iteration 739 ** Loss: 69514.359375\n",
      "Epoch 740 ** iteration 740 ** Loss: 69510.5078125\n",
      "Epoch 741 ** iteration 741 ** Loss: 69507.65625\n",
      "Epoch 742 ** iteration 742 ** Loss: 69507.0546875\n",
      "Epoch 743 ** iteration 743 ** Loss: 69498.7890625\n",
      "Epoch 744 ** iteration 744 ** Loss: 69493.625\n",
      "Epoch 745 ** iteration 745 ** Loss: 69489.2578125\n",
      "Epoch 746 ** iteration 746 ** Loss: 69484.9453125\n",
      "Epoch 747 ** iteration 747 ** Loss: 69480.28125\n",
      "Epoch 748 ** iteration 748 ** Loss: 69476.328125\n",
      "Epoch 749 ** iteration 749 ** Loss: 69470.859375\n",
      "Epoch 750 ** iteration 750 ** Loss: 69465.984375\n",
      "Epoch 751 ** iteration 751 ** Loss: 69461.2734375\n",
      "Epoch 752 ** iteration 752 ** Loss: 69456.8203125\n",
      "Epoch 753 ** iteration 753 ** Loss: 69451.515625\n",
      "Epoch 754 ** iteration 754 ** Loss: 69446.1171875\n",
      "Epoch 755 ** iteration 755 ** Loss: 69441.1796875\n",
      "Epoch 756 ** iteration 756 ** Loss: 69446.7578125\n",
      "Epoch 757 ** iteration 757 ** Loss: 69431.96875\n",
      "Epoch 758 ** iteration 758 ** Loss: 69426.046875\n",
      "Epoch 759 ** iteration 759 ** Loss: 69420.5390625\n",
      "Epoch 760 ** iteration 760 ** Loss: 69415.7421875\n",
      "Epoch 761 ** iteration 761 ** Loss: 69409.4140625\n",
      "Epoch 762 ** iteration 762 ** Loss: 69403.9453125\n",
      "Epoch 763 ** iteration 763 ** Loss: 69398.3125\n",
      "Epoch 764 ** iteration 764 ** Loss: 69393.09375\n",
      "Epoch 765 ** iteration 765 ** Loss: 69385.609375\n",
      "Epoch 766 ** iteration 766 ** Loss: 69379.1015625\n",
      "Epoch 767 ** iteration 767 ** Loss: 69373.2265625\n",
      "Epoch 768 ** iteration 768 ** Loss: 69367.7421875\n",
      "Epoch 769 ** iteration 769 ** Loss: 69360.2265625\n",
      "Epoch 770 ** iteration 770 ** Loss: 69353.4921875\n",
      "Epoch 771 ** iteration 771 ** Loss: 69347.5234375\n",
      "Epoch 772 ** iteration 772 ** Loss: 69340.9609375\n",
      "Epoch 773 ** iteration 773 ** Loss: 69333.59375\n",
      "Epoch 774 ** iteration 774 ** Loss: 69326.96875\n",
      "Epoch 775 ** iteration 775 ** Loss: 69319.15625\n",
      "Epoch 776 ** iteration 776 ** Loss: 69312.1953125\n",
      "Epoch 777 ** iteration 777 ** Loss: 69306.0234375\n",
      "Epoch 778 ** iteration 778 ** Loss: 69296.71875\n",
      "Epoch 779 ** iteration 779 ** Loss: 69295.4609375\n",
      "Epoch 780 ** iteration 780 ** Loss: 69282.9296875\n",
      "Epoch 781 ** iteration 781 ** Loss: 69274.96875\n",
      "Epoch 782 ** iteration 782 ** Loss: 69266.8515625\n",
      "Epoch 783 ** iteration 783 ** Loss: 69259.4375\n",
      "Epoch 784 ** iteration 784 ** Loss: 69250.6640625\n",
      "Epoch 785 ** iteration 785 ** Loss: 69242.2734375\n",
      "Epoch 786 ** iteration 786 ** Loss: 69234.1875\n",
      "Epoch 787 ** iteration 787 ** Loss: 69227.2265625\n",
      "Epoch 788 ** iteration 788 ** Loss: 69217.375\n",
      "Epoch 789 ** iteration 789 ** Loss: 69210.1015625\n",
      "Epoch 790 ** iteration 790 ** Loss: 69199.2890625\n",
      "Epoch 791 ** iteration 791 ** Loss: 69189.4609375\n",
      "Epoch 792 ** iteration 792 ** Loss: 69180.3515625\n",
      "Epoch 793 ** iteration 793 ** Loss: 69172.7265625\n",
      "Epoch 794 ** iteration 794 ** Loss: 69161.8125\n",
      "Epoch 795 ** iteration 795 ** Loss: 69151.6328125\n",
      "Epoch 796 ** iteration 796 ** Loss: 69142.109375\n",
      "Epoch 797 ** iteration 797 ** Loss: 69132.984375\n",
      "Epoch 798 ** iteration 798 ** Loss: 69120.96875\n",
      "Epoch 799 ** iteration 799 ** Loss: 69109.6875\n",
      "Epoch 800 ** iteration 800 ** Loss: 69098.5703125\n",
      "Epoch 801 ** iteration 801 ** Loss: 69088.1875\n",
      "Epoch 802 ** iteration 802 ** Loss: 69077.96875\n",
      "Epoch 803 ** iteration 803 ** Loss: 69066.8125\n",
      "Epoch 804 ** iteration 804 ** Loss: 69054.25\n",
      "Epoch 805 ** iteration 805 ** Loss: 69058.9375\n",
      "Epoch 806 ** iteration 806 ** Loss: 69031.71875\n",
      "Epoch 807 ** iteration 807 ** Loss: 69019.78125\n",
      "Epoch 808 ** iteration 808 ** Loss: 69007.375\n",
      "Epoch 809 ** iteration 809 ** Loss: 68993.40625\n",
      "Epoch 810 ** iteration 810 ** Loss: 68979.515625\n",
      "Epoch 811 ** iteration 811 ** Loss: 68965.6015625\n",
      "Epoch 812 ** iteration 812 ** Loss: 68951.828125\n",
      "Epoch 813 ** iteration 813 ** Loss: 68938.2734375\n",
      "Epoch 814 ** iteration 814 ** Loss: 68925.5859375\n",
      "Epoch 815 ** iteration 815 ** Loss: 68909.9609375\n",
      "Epoch 816 ** iteration 816 ** Loss: 68894.5859375\n",
      "Epoch 817 ** iteration 817 ** Loss: 68879.140625\n",
      "Epoch 818 ** iteration 818 ** Loss: 68862.765625\n",
      "Epoch 819 ** iteration 819 ** Loss: 68846.125\n",
      "Epoch 820 ** iteration 820 ** Loss: 68828.9765625\n",
      "Epoch 821 ** iteration 821 ** Loss: 68812.7578125\n",
      "Epoch 822 ** iteration 822 ** Loss: 68820.875\n",
      "Epoch 823 ** iteration 823 ** Loss: 68779.5\n",
      "Epoch 824 ** iteration 824 ** Loss: 68760.0234375\n",
      "Epoch 825 ** iteration 825 ** Loss: 68740.2421875\n",
      "Epoch 826 ** iteration 826 ** Loss: 68668.3984375\n",
      "Epoch 827 ** iteration 827 ** Loss: 68583.3125\n",
      "Epoch 828 ** iteration 828 ** Loss: 68504.453125\n",
      "Epoch 829 ** iteration 829 ** Loss: 68432.8125\n",
      "Epoch 830 ** iteration 830 ** Loss: 68367.1171875\n",
      "Epoch 831 ** iteration 831 ** Loss: 68309.625\n",
      "Epoch 832 ** iteration 832 ** Loss: 68255.6171875\n",
      "Epoch 833 ** iteration 833 ** Loss: 68203.0859375\n",
      "Epoch 834 ** iteration 834 ** Loss: 68155.7421875\n",
      "Epoch 835 ** iteration 835 ** Loss: 68111.5078125\n",
      "Epoch 836 ** iteration 836 ** Loss: 68070.6640625\n",
      "Epoch 837 ** iteration 837 ** Loss: 68036.1640625\n",
      "Epoch 838 ** iteration 838 ** Loss: 67997.59375\n",
      "Epoch 839 ** iteration 839 ** Loss: 67961.3203125\n",
      "Epoch 840 ** iteration 840 ** Loss: 67924.4296875\n",
      "Epoch 841 ** iteration 841 ** Loss: 67888.65625\n",
      "Epoch 842 ** iteration 842 ** Loss: 67854.2578125\n",
      "Epoch 843 ** iteration 843 ** Loss: 67819.1640625\n",
      "Epoch 844 ** iteration 844 ** Loss: 67785.96875\n",
      "Epoch 845 ** iteration 845 ** Loss: 67757.265625\n",
      "Epoch 846 ** iteration 846 ** Loss: 67723.2734375\n",
      "Epoch 847 ** iteration 847 ** Loss: 67684.7734375\n",
      "Epoch 848 ** iteration 848 ** Loss: 67648.8515625\n",
      "Epoch 849 ** iteration 849 ** Loss: 67612.2421875\n",
      "Epoch 850 ** iteration 850 ** Loss: 67576.40625\n",
      "Epoch 851 ** iteration 851 ** Loss: 67540.2421875\n",
      "Epoch 852 ** iteration 852 ** Loss: 67502.5625\n",
      "Epoch 853 ** iteration 853 ** Loss: 67464.5078125\n",
      "Epoch 854 ** iteration 854 ** Loss: 67428.1484375\n",
      "Epoch 855 ** iteration 855 ** Loss: 67386.171875\n",
      "Epoch 856 ** iteration 856 ** Loss: 67345.0625\n",
      "Epoch 857 ** iteration 857 ** Loss: 67300.9609375\n",
      "Epoch 858 ** iteration 858 ** Loss: 67258.2578125\n",
      "Epoch 859 ** iteration 859 ** Loss: 67213.6484375\n",
      "Epoch 860 ** iteration 860 ** Loss: 67168.75\n",
      "Epoch 861 ** iteration 861 ** Loss: 67136.96875\n",
      "Epoch 862 ** iteration 862 ** Loss: 67080.015625\n",
      "Epoch 863 ** iteration 863 ** Loss: 67025.953125\n",
      "Epoch 864 ** iteration 864 ** Loss: 71832.6796875\n",
      "Epoch 865 ** iteration 865 ** Loss: 67319.078125\n",
      "Epoch 866 ** iteration 866 ** Loss: 66981.046875\n",
      "Epoch 867 ** iteration 867 ** Loss: 66861.0078125\n",
      "Epoch 868 ** iteration 868 ** Loss: 66787.84375\n",
      "Epoch 869 ** iteration 869 ** Loss: 66731.4453125\n",
      "Epoch 870 ** iteration 870 ** Loss: 66677.6171875\n",
      "Epoch 871 ** iteration 871 ** Loss: 66624.4921875\n",
      "Epoch 872 ** iteration 872 ** Loss: 66571.0546875\n",
      "Epoch 873 ** iteration 873 ** Loss: 66517.4296875\n",
      "Epoch 874 ** iteration 874 ** Loss: 66463.21875\n",
      "Epoch 875 ** iteration 875 ** Loss: 66409.3828125\n",
      "Epoch 876 ** iteration 876 ** Loss: 66354.578125\n",
      "Epoch 877 ** iteration 877 ** Loss: 66300.6796875\n",
      "Epoch 878 ** iteration 878 ** Loss: 66255.671875\n",
      "Epoch 879 ** iteration 879 ** Loss: 66189.1796875\n",
      "Epoch 880 ** iteration 880 ** Loss: 66132.796875\n",
      "Epoch 881 ** iteration 881 ** Loss: 66077.03125\n",
      "Epoch 882 ** iteration 882 ** Loss: 66021.78125\n",
      "Epoch 883 ** iteration 883 ** Loss: 65962.65625\n",
      "Epoch 884 ** iteration 884 ** Loss: 65904.3359375\n",
      "Epoch 885 ** iteration 885 ** Loss: 65848.5625\n",
      "Epoch 886 ** iteration 886 ** Loss: 65790.109375\n",
      "Epoch 887 ** iteration 887 ** Loss: 65735.75\n",
      "Epoch 888 ** iteration 888 ** Loss: 65675.4453125\n",
      "Epoch 889 ** iteration 889 ** Loss: 65620.15625\n",
      "Epoch 890 ** iteration 890 ** Loss: 65564.0234375\n",
      "Epoch 891 ** iteration 891 ** Loss: 65511.44921875\n",
      "Epoch 892 ** iteration 892 ** Loss: 65458.03125\n",
      "Epoch 893 ** iteration 893 ** Loss: 65409.2265625\n",
      "Epoch 894 ** iteration 894 ** Loss: 65353.1484375\n",
      "Epoch 895 ** iteration 895 ** Loss: 65306.13671875\n",
      "Epoch 896 ** iteration 896 ** Loss: 65250.1171875\n",
      "Epoch 897 ** iteration 897 ** Loss: 65205.34765625\n",
      "Epoch 898 ** iteration 898 ** Loss: 65153.95703125\n",
      "Epoch 899 ** iteration 899 ** Loss: 65110.30078125\n",
      "Epoch 900 ** iteration 900 ** Loss: 65056.78125\n",
      "Epoch 901 ** iteration 901 ** Loss: 65010.609375\n",
      "Epoch 902 ** iteration 902 ** Loss: 64963.234375\n",
      "Epoch 903 ** iteration 903 ** Loss: 64920.12890625\n",
      "Epoch 904 ** iteration 904 ** Loss: 64874.00390625\n",
      "Epoch 905 ** iteration 905 ** Loss: 64840.15234375\n",
      "Epoch 906 ** iteration 906 ** Loss: 64792.3203125\n",
      "Epoch 907 ** iteration 907 ** Loss: 64749.9921875\n",
      "Epoch 908 ** iteration 908 ** Loss: 64700.25390625\n",
      "Epoch 909 ** iteration 909 ** Loss: 64668.30859375\n",
      "Epoch 910 ** iteration 910 ** Loss: 64623.3359375\n",
      "Epoch 911 ** iteration 911 ** Loss: 64585.13671875\n",
      "Epoch 912 ** iteration 912 ** Loss: 64550.65234375\n",
      "Epoch 913 ** iteration 913 ** Loss: 64526.0703125\n",
      "Epoch 914 ** iteration 914 ** Loss: 64482.97265625\n",
      "Epoch 915 ** iteration 915 ** Loss: 64456.015625\n",
      "Epoch 916 ** iteration 916 ** Loss: 64415.2734375\n",
      "Epoch 917 ** iteration 917 ** Loss: 64385.38671875\n",
      "Epoch 918 ** iteration 918 ** Loss: 64345.31640625\n",
      "Epoch 919 ** iteration 919 ** Loss: 64326.30859375\n",
      "Epoch 920 ** iteration 920 ** Loss: 64283.01171875\n",
      "Epoch 921 ** iteration 921 ** Loss: 64251.46875\n",
      "Epoch 922 ** iteration 922 ** Loss: 64224.37890625\n",
      "Epoch 923 ** iteration 923 ** Loss: 64209.8359375\n",
      "Epoch 924 ** iteration 924 ** Loss: 64189.328125\n",
      "Epoch 925 ** iteration 925 ** Loss: 64175.03515625\n",
      "Epoch 926 ** iteration 926 ** Loss: 64131.01171875\n",
      "Epoch 927 ** iteration 927 ** Loss: 64117.0859375\n",
      "Epoch 928 ** iteration 928 ** Loss: 64036.5\n",
      "Epoch 929 ** iteration 929 ** Loss: 64002.54296875\n",
      "Epoch 930 ** iteration 930 ** Loss: 63976.0234375\n",
      "Epoch 931 ** iteration 931 ** Loss: 63949.546875\n",
      "Epoch 932 ** iteration 932 ** Loss: 63921.40625\n",
      "Epoch 933 ** iteration 933 ** Loss: 63904.078125\n",
      "Epoch 934 ** iteration 934 ** Loss: 63905.54296875\n",
      "Epoch 935 ** iteration 935 ** Loss: 63844.53125\n",
      "Epoch 936 ** iteration 936 ** Loss: 63817.61328125\n",
      "Epoch 937 ** iteration 937 ** Loss: 63804.44921875\n",
      "Epoch 938 ** iteration 938 ** Loss: 63802.2734375\n",
      "Epoch 939 ** iteration 939 ** Loss: 63739.125\n",
      "Epoch 940 ** iteration 940 ** Loss: 63712.44921875\n",
      "Epoch 941 ** iteration 941 ** Loss: 63691.90234375\n",
      "Epoch 942 ** iteration 942 ** Loss: 63675.203125\n",
      "Epoch 943 ** iteration 943 ** Loss: 63678.8515625\n",
      "Epoch 944 ** iteration 944 ** Loss: 63681.5703125\n",
      "Epoch 945 ** iteration 945 ** Loss: 63599.14453125\n",
      "Epoch 946 ** iteration 946 ** Loss: 63574.296875\n",
      "Epoch 947 ** iteration 947 ** Loss: 63560.24609375\n",
      "Epoch 948 ** iteration 948 ** Loss: 63561.06640625\n",
      "Epoch 949 ** iteration 949 ** Loss: 63562.8828125\n",
      "Epoch 950 ** iteration 950 ** Loss: 63490.8046875\n",
      "Epoch 951 ** iteration 951 ** Loss: 63467.6484375\n",
      "Epoch 952 ** iteration 952 ** Loss: 63452.91796875\n",
      "Epoch 953 ** iteration 953 ** Loss: 63443.12890625\n",
      "Epoch 954 ** iteration 954 ** Loss: 63453.60546875\n",
      "Epoch 955 ** iteration 955 ** Loss: 63386.28515625\n",
      "Epoch 956 ** iteration 956 ** Loss: 63360.77734375\n",
      "Epoch 957 ** iteration 957 ** Loss: 63343.1484375\n",
      "Epoch 958 ** iteration 958 ** Loss: 63345.64453125\n",
      "Epoch 959 ** iteration 959 ** Loss: 63413.78515625\n",
      "Epoch 960 ** iteration 960 ** Loss: 63364.11328125\n",
      "Epoch 961 ** iteration 961 ** Loss: 63310.484375\n",
      "Epoch 962 ** iteration 962 ** Loss: 63256.1875\n",
      "Epoch 963 ** iteration 963 ** Loss: 63239.00390625\n",
      "Epoch 964 ** iteration 964 ** Loss: 63242.44140625\n",
      "Epoch 965 ** iteration 965 ** Loss: 63275.703125\n",
      "Epoch 966 ** iteration 966 ** Loss: 63248.4375\n",
      "Epoch 967 ** iteration 967 ** Loss: 63195.05078125\n",
      "Epoch 968 ** iteration 968 ** Loss: 63220.46484375\n",
      "Epoch 969 ** iteration 969 ** Loss: 63209.2421875\n",
      "Epoch 970 ** iteration 970 ** Loss: 63147.3359375\n",
      "Epoch 971 ** iteration 971 ** Loss: 63159.20703125\n",
      "Epoch 972 ** iteration 972 ** Loss: 63154.609375\n",
      "Epoch 973 ** iteration 973 ** Loss: 63090.28515625\n",
      "Epoch 974 ** iteration 974 ** Loss: 63088.69921875\n",
      "Epoch 975 ** iteration 975 ** Loss: 63094.92578125\n",
      "Epoch 976 ** iteration 976 ** Loss: 63035.578125\n",
      "Epoch 977 ** iteration 977 ** Loss: 63019.66796875\n",
      "Epoch 978 ** iteration 978 ** Loss: 63016.19140625\n",
      "Epoch 979 ** iteration 979 ** Loss: 63037.2578125\n",
      "Epoch 980 ** iteration 980 ** Loss: 63036.8359375\n",
      "Epoch 981 ** iteration 981 ** Loss: 62987.45703125\n",
      "Epoch 982 ** iteration 982 ** Loss: 63023.72265625\n",
      "Epoch 983 ** iteration 983 ** Loss: 63004.8046875\n",
      "Epoch 984 ** iteration 984 ** Loss: 62957.01171875\n",
      "Epoch 985 ** iteration 985 ** Loss: 62908.23828125\n",
      "Epoch 986 ** iteration 986 ** Loss: 62899.8359375\n",
      "Epoch 987 ** iteration 987 ** Loss: 62898.15625\n",
      "Epoch 988 ** iteration 988 ** Loss: 62940.73046875\n",
      "Epoch 989 ** iteration 989 ** Loss: 62934.234375\n",
      "Epoch 990 ** iteration 990 ** Loss: 62884.60546875\n",
      "Epoch 991 ** iteration 991 ** Loss: 62830.72265625\n",
      "Epoch 992 ** iteration 992 ** Loss: 62826.49609375\n",
      "Epoch 993 ** iteration 993 ** Loss: 62836.66796875\n",
      "Epoch 994 ** iteration 994 ** Loss: 62785.16796875\n",
      "Epoch 995 ** iteration 995 ** Loss: 62773.08203125\n",
      "Epoch 996 ** iteration 996 ** Loss: 62766.03125\n",
      "Epoch 997 ** iteration 997 ** Loss: 62780.03125\n",
      "Epoch 998 ** iteration 998 ** Loss: 62798.640625\n",
      "Epoch 999 ** iteration 999 ** Loss: 62734.3359375\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "gae.train(1000, update_interval=1, threshold=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00892208-ae4c-4a89-94c1-d4120f42d397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gae.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d6b59-47fa-44ea-8576-8fa07c1c65a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grafiti",
   "language": "python",
   "name": "grafiti"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
